
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Automated Empirical Optimisation of Parameters in Owl &#8212; Owl Numerical Library 0.7 documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />

   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

<meta name="description" content="OCaml Scientific and Engineering Computing">
<meta name="keywords" content="OCaml, Data Science, Data Analytics, Analytics, Functional Programming, Machine Learning, Deep Neural Network, Scientific Computing, Numerical Algorithm, Tutorial, Linear Algebra, Matrix">
<meta name="author" content="Liang Wang">
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123353217-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-123353217-1');
</script>
<!-- Google AdSense -->
<script data-ad-client="ca-pub-1868946892712371" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- Media.Net -->
<script type="text/javascript">
  window._mNHandle = window._mNHandle || {};
  window._mNHandle.queue = window._mNHandle.queue || [];
  medianet_versionId = "3121199";
</script>
<script src="https://contextual.media.net/dmedianet.js?cid=8CU51B3CU" async="async"></script>

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/owl_logo_4.png" alt="Logo"/>
    
  </a>
</p>











  <h3><a href="../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Automated Empirical Optimisation of Parameters in Owl</a><ul>
<li><a class="reference internal" href="#use-openmp-to-boost-computation">Use OpenMP to boost computation</a><ul>
<li><a class="reference internal" href="#why-simple-solution-does-not-work">Why simple solution does not work</a></li>
</ul>
</li>
<li><a class="reference internal" href="#implementation">Implementation</a></li>
<li><a class="reference internal" href="#evaluation">Evaluation</a></li>
<li><a class="reference internal" href="#whats-next">What’s next?</a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="automated-empirical-optimisation-of-parameters-in-owl">
<h1>Automated Empirical Optimisation of Parameters in Owl<a class="headerlink" href="#automated-empirical-optimisation-of-parameters-in-owl" title="Permalink to this headline">¶</a></h1>
<p>by Jianxin Zhao</p>
<p>Recent research on <em>parameter tuning</em> mostly focus on hyper-parameter tuning, such as optimising the parameters of stochastic gradient in machine learning applications.
However, tuning code and parameters in low-level numerical libraries is of the same importance.
For example, <a class="reference external" href="http://math-atlas.sourceforge.net/">ATLAS</a> and the recent <a class="reference external" href="https://software.intel.com/mkl">Intel Math Kernel Library (MKL)</a> are both software libraries of optimised math routines for science and engineering computation.
They are widely used in many popular high-level platforms such as Matlab and  TensorFlow.
One of the reasons these libraries can provide optimal performance is that they have adopted the paradigm of Automated Empirical Optimisation of Software, or AEOS.
That is, a library chooses the best method and parameter to use on a given platform to do a required operation.
One highly optimised routine may run much faster than a naively coded one.
Naturally, optimised code is usually platform- and hardware-specific. An optimised routine on one machine usually performs bad on the other.</p>
<p>Though <a class="reference external" href="http://ocaml.xyz/">Owl</a>  currently does not plan to improve the low-level libraries it depends on, as an initial endeavour to apply the AEOS paradigm in Owl, one ideal tuning point is the parameters of OpenMP used in Owl.</p>
<div class="section" id="use-openmp-to-boost-computation">
<h2>Use OpenMP to boost computation<a class="headerlink" href="#use-openmp-to-boost-computation" title="Permalink to this headline">¶</a></h2>
<p>Currently many computers contain shared memory multiprocessors.
<a class="reference external" href="https://www.openmp.org/">OpenMP</a> is an application programming interface that supports multi-platform shared memory multiprocessing programming in C or Fortran, supported on a plethora of hardware and software platforms.
It is used in key operations in libraries such as Eigen and MKL.
Owl has also utilised OpenMP on many math operations to boost their performance by threading calculation.</p>
<p>For example, the figure below shows that when we apply the <span class="math notranslate nohighlight">\(sin\)</span> function on a N-Dimensional Array (ndarray) in Owl, on a 4-core CPU MacBook, the OpenMP version only takes about a third of the execution time compared with the non-OpenMP version.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../_images/owl_aeos_sin_perf_mac.png"><img alt="omp_sin" src="../_images/owl_aeos_sin_perf_mac.png" style="width: 70%;" /></a>
</div>
<p>However, as is often the case, performance improvement does not come for free.
Overhead of using OpenMP comes from time spent on scheduling chunks of work to each thread, managing locks on critical sections, and startup time of creating threads, etc.
Therefore, when the input ndarray is small enough, these overheads might overtake the benefit of threading.
Now the question is, what is a suitable input size to use OpenMP?</p>
<div class="section" id="why-simple-solution-does-not-work">
<h3>Why simple solution does not work<a class="headerlink" href="#why-simple-solution-does-not-work" title="Permalink to this headline">¶</a></h3>
<p>This question would be easy to solve if there is one single suitable input size threshold for every operation.
Alas, that’s not the case. Let’s do a small experiment.
We compare the performance of two operations, <span class="math notranslate nohighlight">\(abs\)</span> (calculate absolute value) and <span class="math notranslate nohighlight">\(sin\)</span>, in three cases: running them without using OpenMP, with 2 threads OpenMP, and with 4 threads OpenMP.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../_images/owl_aeos_cross.png"><img alt="omp_cross" src="../_images/owl_aeos_cross.png" style="width: 90%;" /></a>
</div>
<p>The result shows that, with growing input size, for <span class="math notranslate nohighlight">\(sin\)</span> operation, the OpenMP version outperforms the non-OpenMP version at a size of less than 1000, but for <span class="math notranslate nohighlight">\(abs\)</span> operation, that crosspoint is at about 1,000,000.
The <a class="reference external" href="https://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations">complexity of math operations</a> varies greatly, and the difference is even starker when compare their performance on different machines.</p>
<p>This issue becomes more complex when considered in real applications.
We know that even advanced computation such as training and inference of neural networks can be seen as a computation graph, each node being basic math operations such as <span class="math notranslate nohighlight">\(conv\)</span>, <span class="math notranslate nohighlight">\(dot\)</span>, <span class="math notranslate nohighlight">\(sigmoid\)</span>, <span class="math notranslate nohighlight">\(uniform\)</span>, etc.
In a computation graph, we need to deal with operations of vastly different complexity and input sizes.
Thus one fixed threshold for several operations is not an ideal solution.</p>
<p>Considering these factors, we need a fine-grained method to decide a suitable threshold for each operation.</p>
</div>
</div>
<div class="section" id="implementation">
<h2>Implementation<a class="headerlink" href="#implementation" title="Permalink to this headline">¶</a></h2>
<p>Towards this end, we implement the AEOS module.
The idea is to add a <em>tuning</em> phase before compiling and installing Owl, so that each operation learns a suitable threshold parameter to decide if OpenMP should be used or not, depending on input size.</p>
<p>The key idea of parameter tuning is simple.
We implement two versions of each operation, one using OpenMP and the other not. We then measure their execution time for various sizes of input.
Each measurement is repeated multiple times, and to reduce the effect of outliers, only the values that are within first and third percentiles are used.
After removing outliers, regression is performed to find a suitable input size threshold.
According to our initial experiment, linear regression is fit to estimate the OpenMP parameters here.</p>
<p>Since this tuning phase is executed before compiling Owl, the AEOS module is made independent of Owl, and all the necessary implementation are coded separately to ensure that future changes of Owl do not affect the AEOS module itself.</p>
<p>The tuned parameters then need to be passed to Owl.
When the OpenMP switch is turned on, the AEOS module generates a C header file which contains the definition of macros, each of which defines a threshold for one operation. When this header file is not generated, pre-defined default macro values are used instead.
After that, Owl is compiled with this header file and uses these tuned parameters in its math operations.
The tuning phase only needs to be performed once on each machine.</p>
<p>The design of the AEOS module focuses on keeping tuning simple, effective, and flexible.
Each operation is implemented as a single OCaml module, so that support for new operations can be easily added.
The interface of a module is shown as below:</p>
<div class="highlight-ocaml notranslate"><div class="highlight"><pre><span></span><span class="k">module</span> <span class="nc">Sin</span> <span class="o">=</span> <span class="k">struct</span>

  <span class="k">type</span> <span class="n">t</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">mutable</span> <span class="n">name</span>  <span class="o">:</span> <span class="kt">string</span><span class="o">;</span>
    <span class="k">mutable</span> <span class="n">param</span> <span class="o">:</span> <span class="kt">string</span><span class="o">;</span>
    <span class="k">mutable</span> <span class="k">value</span> <span class="o">:</span> <span class="kt">int</span><span class="o">;</span>
    <span class="k">mutable</span> <span class="n">input</span> <span class="o">:</span> <span class="kt">int</span> <span class="kt">array</span> <span class="kt">array</span><span class="o">;</span>
    <span class="k">mutable</span> <span class="n">y</span>     <span class="o">:</span> <span class="kt">float</span> <span class="kt">array</span>
  <span class="o">}</span>
  <span class="c">(** Tuner type definition. *)</span>

  <span class="k">val</span> <span class="n">make</span> <span class="o">:</span> <span class="kt">unit</span> <span class="o">-&gt;</span> <span class="n">t</span>
  <span class="c">(** Create the tuner. *)</span>

  <span class="k">val</span> <span class="n">tune</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
  <span class="c">(** Tuning process. *)</span>

  <span class="k">val</span> <span class="n">save_data</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">unit</span>
  <span class="c">(** Save tuned data to csv file for later analysis. *)</span>

  <span class="k">val</span> <span class="n">to_string</span> <span class="o">:</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="kt">string</span>
  <span class="c">(** Convert the tuned parameter(s) to string to be written on file *)</span>

<span class="k">end</span>
</pre></div>
</div>
<p>We expect that tuning does not have to be only about OpenMP parameters, and that different regression methods could be used in the future.
For example, the <a class="reference external" href="https://www.tandfonline.com/doi/abs/10.1080/01621459.1968.10480934">Theil–Sen estimator</a> can be plugged in for parameter estimation if necessary.
In each module, arbitrary tuning procedures can be plugged in as long as the interface is satisfied.</p>
<p>The AEOS module is implemented in such way that brings little interference to the main Owl library. Code can be viewed in this <a class="reference external" href="https://github.com/owlbarn/owl/pull/332">pull request</a>, and has been merged into the main branch of Owl. You only need to switch the <em>ENABLE_OPENMP</em> flag from <span class="math notranslate nohighlight">\(0\)</span> to <span class="math notranslate nohighlight">\(1\)</span> in the <a class="reference external" href="https://github.com/owlbarn/owl/blob/master/src/owl/dune">dune file</a> to try this feature.</p>
</div>
<div class="section" id="evaluation">
<h2>Evaluation<a class="headerlink" href="#evaluation" title="Permalink to this headline">¶</a></h2>
<p>To evaluate the performance of tuned OpenMP thresholds, we need a metric to compare them.
One metric to compare two thresholds is proposed as below. We generate a series of ndarrays, whose sizes grow by certain steps until they reach a given maximum number, e.g. 1,000,000 used in the experiment below.
Note that only input sizes that fall between these two thresholds are chosen to be used.
We then calculate the performance improvement ratio of the OpenMP version function over the non-OpenMP version on these chosen ndarrays. The ratios are added up, and then amortised by the total number of ndarrays.
Hereafter we use this averaged ratio as performance metric.</p>
<blockquote>
<div><table border="1" class="docutils">
<colgroup>
<col width="17%" />
<col width="16%" />
<col width="17%" />
<col width="16%" />
<col width="16%" />
<col width="19%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>Platform</td>
<td><span class="math notranslate nohighlight">\(tan\)</span></td>
<td><span class="math notranslate nohighlight">\(sqrt\)</span></td>
<td><span class="math notranslate nohighlight">\(sin\)</span></td>
<td><span class="math notranslate nohighlight">\(exp\)</span></td>
<td><span class="math notranslate nohighlight">\(sigmoid\)</span></td>
</tr>
<tr class="row-even"><td>MacBook</td>
<td>1632</td>
<td>max_int</td>
<td>1294</td>
<td>123</td>
<td>1880</td>
</tr>
<tr class="row-odd"><td>Raspberry Pi</td>
<td>1189</td>
<td>209</td>
<td>41</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
</div></blockquote>
<p>This table presents the tuned threshold values of a five operations on a MacBook with a 1.1GHz Intel Core m3 CPU and a Raspberry Pi 3B.
We can see that they vary across different operations and different machines, depending on their computation complexity.
For example, on MacBook, the tuning result is “max_int”, which means that for the relatively simple <span class="math notranslate nohighlight">\(sqrt\)</span> calculation OpenMP should not be used, but that’s not the case on Raspberry Pi. Also, we note that the less powerful Raspberry Pi tends to get lower thresholds.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../_images/owl_aeos_perf.png"><img alt="aeos mac" src="../_images/owl_aeos_perf.png" style="width: 100%;" /></a>
</div>
<p>We then evaluate the performance improvement after applying AEOS.
We compare each generated parameter with 30 random generated thresholds. These measured average ratios are then presented as a box plot, as shown in the figure above.</p>
<p>It can be observed that in general more than 20% average performance improvement can be expected on the MacBook.
The result on Raspberry Pi shows a larger deviation but also a higher performance gain (about 30% on average).
One reason of this difference could be that a suitable threshold on Raspberry Pi tends to be smaller, leading to a larger probability to outperform a randomly generated value.
Note that we cannot proclaim that the tuned parameters are always optimal, since the figure shows that in some rare cases where the improvement percentages are minus, the randomly found values indeed perform better.
Also, the result seems to suggest that AEOS can provide a certain bound, albeit a loose one, on the performance improvement, regardless of the type of operation.
These interesting issues requires further investigation.</p>
</div>
<div class="section" id="whats-next">
<h2>What’s next?<a class="headerlink" href="#whats-next" title="Permalink to this headline">¶</a></h2>
<p>As said above, this is an initial effort to apply the AEOS paradigm in Owl. Though the result looks promising, there still exists many interesting questions to further explore.
For example, analysis on single operation should be extended to practical applications.
Different regression methods could also be applied.
More operations that require tuning more than just OpenMP parameters could be included.
In evaluation, besides performance, stability of the generated parameters might also need to be considered to give a full picture in evaluation.</p>
</div>
</div>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>

    <div class="footer">
      &copy;2018-2020, <a href="http://www.cl.cam.ac.uk/~lw525/">Liang Wang</a>   | <a href="http://www.cl.cam.ac.uk/">Computer Lab, University of Cambridge</a>.
      
      |
      <a href="../_sources/project/jianxin_aeos.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
<!-- Extra footer if necessary -->
<div id="383268675">
  <script type="text/javascript">
      try {
          window._mNHandle.queue.push(function (){
              window._mNDetails.loadTag("383268675", "970x90", "383268675");
          });
      }
      catch (error) {}
  </script>
</div>

  </body>
</html>